<?xml version="1.0"?>
<record where="s" when="1196701202" ordinal="20" title="ROADRUNNER COMPUTER">
  <narrative>ROADRUNNER COMPUTER -- (Senate - December 03, 2007)&lt;p&gt;&lt;center&gt;&lt;pre&gt;[Page: <bill type="s" number="14695">S14695</bill>]</narrative>
  <speaking speaker="300036" topic="">
    <paragraph>Mr. President, today's Washington Post Science section contains an excellent summary on the work America is doing to develop the fastest computers in the world and the benefits to all of us from such computers.</paragraph>
    <paragraph>The headline on the story, "Faster Computers Accelerate Pace of Discovery," captures today and hints at tomorrow for science, using computers that have processing speeds of more than a thousand trillion calculations per second. That speed is known as a petaflop, in computer science speak.</paragraph>
    <paragraph>I am proud that the first petaflop computer in the world is likely to be at Los Alamos National Laboratory in my home State of New Mexico. Working in conjunction with IBM, LANL's "Roadrunner" computer holds out the promise of immense advances in almost every aspect of scientific inquiry.</paragraph>
    <paragraph>In the area of nuclear weapons, for example, computing power increases are critical. Two decades ago, this Nation decided to stop underground testing of nuclear weapons. Yet the necessity of certifying the reliability and performance of our nuclear stockpile remains. How could we do away with underground testing and still have the three weapons lab directors certify to the President that our weapons were safe and reliable. We decided to adopt a program called Science-Based Stockpile Stewardship.  Essentially, we decided to simulate a nuclear weapons explosion using computer power. Clearly, America needed more computing power when we made this decision. "Roadrunner" is an important step toward making sure that our nuclear stockpile will work if ever needed.</paragraph>
    <paragraph>One of the most interesting uses of this enormous computer power is modeling climate change. It is ironic that many of those who oppose additional funding for the national laboratories want a more aggressive stance on the question of climate change and ways to ameliorate it, are the same people who support a House-passed Energy and Water Appropriations bill that would reject more funding for "Roadrunner."</paragraph>
    <paragraph>Mr. President, we are in the middle of negotiations on the Energy and Water appropriations bill right now. Adoption of the House-passed bill will not only set back our work on computing power and climate change but will be a disaster for certification of the reliability of our nuclear weapons. I hope that all Members of Congress will read today's article in the Washington Post to get an idea of what is at stake as we set policy in the future.</paragraph>
    <paragraph>Mr. President, I ask unanimous consent that the entire article be printed in the Record.</paragraph>
  </speaking>
  <narrative>There being no objection, the material was ordered to be printed in the RECORD, as follows:</narrative>
  <narrative>[From the Washington Post, Dec. 3, 2007]</narrative>
  <narrative>Faster Computers Accelerate Pace of Discovery</narrative>
  <narrative>(by Christopher Lee)</narrative>
  <narrative>Sometime next year, developers will boot up the next generation of supercomputers, machines whose vast increases in processing power will accelerate the transformation of the scientific method, experts say.</narrative>
  <narrative>The first "petascale" supercomputer will be capable of 1,000 trillion calculations per second. That's about twice as powerful as today's dominant model, a basketball-court-size beast known as BlueGene/L, at the Energy Department's Lawrence Livermore National Laboratory in California that performs a peak of 596 trillion calculations per second.</narrative>
  <narrative>The computing muscle of the new petascale machines will be akin to that of more than 100,000 desktop computers combined, experts say. A computation that would take a lifetime for a home PC and that can be completed in about five hours on today's supercomputers will be doable in as little as two hours.</narrative>
  <narrative>"The difficulty in building the machines is tremendous, and the amount of power these machines require is pretty mind-boggling," said Mark Seager, assistant department head for advanced computing technology at Lawrence Livermore. "But the scientific results that we can get out of them are also mind-boggling and worth every penny and every megawatt it takes to build them."</narrative>
  <narrative>A leading candidate to become the first petascale machine, the "Roadrunner" supercomputer being developed by IBM in partnership with the Energy Department's Los Alamos National Laboratory, will require about 4 megawatts of power--enough to illuminate 10,000 light bulbs, said John Hopson, program director for advanced simulation and computing at Los Alamos in New Mexico.</narrative>
  <narrative>But scientists say Roadrunner and its cousins will make possible dramatically improved computer simulations. That will help shed new light on subjects such as climate change, geology, new drug development, dark matter and other secrets of the universe, as well as other fields in which direct experimental observation is time-consuming, costly, dangerous or impossible.</narrative>
  <narrative>In fact, supercomputers and their simulations are becoming so powerful that they essentially have introduced a new step in the time-honored scientific method that moves from theory to hypothesis to experimental confirmation, some experts contend.</narrative>
  <narrative>"They are a tool that really helps stimulate the imagination of scientists and engineers in ways that previously weren't possible," said David Turek, vice president of supercomputing at IBM. "You had theory and hypothesis and experimentation. Well, now scientists are admitting that computation is an  important part of this, as well."</narrative>
  <narrative>"Nature is the final arbiter of truth," said Seager, the Lawrence Livermore computer scientist, but "rather than doing experiments, a lot of times now we're actually simulating those experiments and getting the data that way.</narrative>
  <narrative>"We can now do as much scientific discovery with computational science as we could do before with observational science or theoretical science."</narrative>
  <narrative>A particularly fruitful area of computer modeling has been the study of global climate change. Ten years ago, experts agreed that humans probably were contributing to global warming. Now, in part because of a 10,000-fold increase computing power and better accuracy in climate simulations, scientists are sure of it.</narrative>
  <narrative>One result is that computer climate models can now simulate atmospheric and oceanic conditions and, crucially, how changes in each affect the other, experts said. Now the worry is not that computing power is inadequate but that the aging of NASA's weather satellites will lead to a shortage of input data before long, Seager and others said.</narrative>
  <narrative>Petascale computers also will make it possible to predict, say, the effect of an earthquake on every building in downtown Los Angeles, experts said. Current models cannot yield predictions for areas smaller than a square mile or two. The increased detail could help shape building codes and be a valuable tool in evacuation planning and disaster preparedness.</narrative>
  <narrative>Computer simulations also help assess the reliability, safety, security and performance of weapons in the U.S. nuclear stockpile, years removed from any real-life nuclear tests. "Nuclear weapons are the quintessential example of something you can't really test anymore, so a lot of it has to be done computationally," said Hopson, the Los Alamos scientist.</narrative>
  <narrative>Other potential uses of petascale computers include better simulations of what happens when stars explode into supernovas and die, and new and more refined analyses of experimental drugs and their effects on disease and interactions with other medications, experts said.</narrative>
  <narrative>Still another is the modeling of the bird flu virus and how it might evolve to become more communicable and lethal--knowledge that could help scientists develop a vaccine in time to use it and to inform public health planning. Petascale computers are also expected to lead to more potent models for Wall Street to calculate risk and predict the fate of financial instruments, as well as more advanced digital prototypes of automobiles and jet aircraft, further reducing the need for physical mock-ups.</narrative>
  <narrative>The remarkable advances in computing power of recent decades are frequently attributed to the tenet known as Moore's Law, named for Intel co-founder Gordon E. Moore, which says that progress in building chips doubles the power of microprocessors about every 18 months. But that alone does not explain the leaps in supercomputing, scientists said.</narrative>
  <narrative>Today's supercomputers rely not only on better "compute nodes" (made up of faster chips and more memory), but also on scientists' ability to "gang" hundreds of thousands of those nodes together in a single machine and to devise better ways of having them communicate with one another and divide up the work of complex problem solving.</narrative>
  <narrative>"If you ran today's code on yesterday's computers, they would be much faster," said Raymond Bair, director of the Argonne Leadership Computing Facility at the Energy Department's Argonne National Laboratory near Chicago. "People have figured out how to solve the problems faster."</narrative>
  <narrative>Even before a petascale computer is a reality, scientists are anticipating the next big milestone, the exascale machine--a thousand times more powerful still, and capable of 1 million trillion calculations per second. But they'll have to wait. That one isn't expected until about 2018.</narrative>
</record>
